{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H1UHb_YpGsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "def sigmoid_activation(X):\n",
        "    return 1.0/(1+np.exp(-X))\n",
        "def predict(X, W):\n",
        "    preds= sigmoid_activation(X.dot(W))\n",
        "    preds[preds <= 0.5]= 0\n",
        "    preds[preds > 0 ] = 1 \n",
        "    return preds\n",
        "    \n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-e\", \"--epochs\", type=float, default =100, help=\"# of epochs\")\n",
        "ap.add_argument(\"-a\",\"--alpha\", type= float, default =0.01, help= \"learning rate\")\n",
        "args = vars(ap.parse_args())\n",
        " \n",
        "\n",
        "(X,y) = make_blobs(n_samples =1000, n_features =2, centers =2, cluster_std=1.5, random_state =1)\n",
        "y = y.reshape((y.shape[0],1))\n",
        "\n",
        "X = np.c_[X, np.ones((X.shape[0]))]\n",
        "\n",
        "(trainX, testX, trainY, testY)= train_test_split(X,y,test_size = 0.5, random_state=42)\n",
        "print(\"[INFO] training...\")\n",
        "W = np.random.randn(X.shape[1],1)\n",
        "losses = []\n",
        "\n",
        "for epoch in np.arange(0, args[\"epochs\"]):\n",
        "  preds= sigmoid_activation(trainX.dot(W))\n",
        "  error = preds - trainY\n",
        "  loss = np.sum(error ** 2)\n",
        "  losses.append(loss)\n",
        "    \n",
        "gradient = trainX.T.dot(error)\n",
        "W += -args[\"alpha\"]* gradient\n",
        "\n",
        "if epoch == 0 or (epoch + 1)% 5 == 0:\n",
        "    print(\"[INFO] epoch= {}, loss={:.7f}\".format(int(epoch+1),loss))\n",
        "print(\"[INFO] evaluating...\")\n",
        "\n",
        "preds= predict(testX, W)\n",
        "print(classification_report(testY, preds))\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.title(\"Data\")\n",
        "plt.scatter(testX[:, 0],testX[:,1], marker=\"0\", c=testY, s=30)\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arrange(0,args[\"epochs\"],losses))\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}